# -*- coding: utf-8 -*-
"""codes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IjbbZgPbhCadDNMrxnjDnXgIEWepnFCo
"""

import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/CSE/CSE424/Final Project/Codes/TrafficTwoMonth.csv')
df.head(100)

df[df['Traffic Situation'] != 'normal']

df.shape

import matplotlib.pyplot as plt

# in our dataset first 96 entries means 1 day(15*96 = 1440mins = 1 day)
df_first_day = df.iloc[:96]

plt.figure(figsize=(12, 6))
plt.plot(df_first_day['Time'], df_first_day['Total'])
plt.xlabel('Time')
plt.ylabel('Total')
plt.title('Total vs. Time (First Day)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
plt.figure(figsize=(18, 6))
plt.plot(df_first_day['Time'], df_first_day['Traffic Situation'])
plt.xlabel('Time')
plt.ylabel('Traffic Situation')
plt.title('Traffic Situation vs. Time (First Day)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#Changed the date to year-month-date format

df_first_day = df.iloc[:96]# 1 day

#after 1 day which is 96 rows in the dataset day increases by one
import datetime

df['Date'] = pd.to_datetime('2023-12-10')

for i in range(0, len(df), 96):
  if i + 96 <= len(df):
    df.loc[i:i+95, 'Date'] = df.loc[i, 'Date']
    next_date = df.loc[i, 'Date'] + datetime.timedelta(days=1)
    if i+96 < len(df):
      df.loc[i+96, 'Date'] = next_date

df.head(5992)

#switched places of date and time
cols = list(df.columns)

date_index = cols.index('Date')
time_index = cols.index('Time')

cols.pop(date_index)
cols.pop(time_index)

cols.insert(0, 'Date')
cols.insert(1, 'Time')


df = df[cols]

df.head(100)

import matplotlib.pyplot as plt

plt.hist(df['Traffic Situation'])
plt.xlabel('Traffic Situation')
plt.ylabel('Frequency')
plt.title('Histogram of Traffic Situation')
plt.xticks(rotation=45)
plt.show()

# Split the for train-test data
train = df.iloc[:-200]
test = df.iloc[-200:]
test.head()

from statsmodels.tsa.arima.model import ARIMA

model = ARIMA(train.Total, order=(2, 1, 0))
results = model.fit()

#predictions for the test set
forecast = results.forecast(steps=200)
forecast

#error calculation
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

#mean absolute error
test_Total = test['Total']
mae = mean_absolute_error(test_Total, forecast)

#root mean square error
mse = mean_squared_error(test_Total, forecast)
rmse = np.sqrt(mse)

#mean absolute percentage error
mape = (forecast - test_Total).abs().div(test_Total).mean()

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAPE: {mape:.2f}%")

import matplotlib.pyplot as plt
plt.figure(figsize=(18, 6))
plt.plot(train['Total'], label='Train')
plt.plot(test['Total'], label='Test')
plt.plot(test.index, forecast, label='Forecast')
plt.xlabel('Time')
plt.ylabel('Total')
plt.title('Train, Test, and Forecast')
plt.legend()
plt.show()

accuracy = 100 - (mape * 100)
print(f"Accuracy: of Arima Model is {accuracy:.2f}%")

!pip install prophet

# time column as ds and target as y are mandatory
df_p = df.reset_index()[["Time", "Total"]].rename(
   columns={"Time": "ds", "Total": "y"}
)
df_p.head()

import pandas as pd
from prophet import Prophet


model = Prophet()

model.fit(df_p)

# create date to predict
future_dates = model.make_future_dataframe(periods=365)
# Make predictions
predictions = model.predict(future_dates)
predictions.head()

model.plot(predictions)

#used date instead of time
df_p = df.reset_index()[["Date", "Total"]].rename(
   columns={"Date": "ds", "Total": "y"}
)
df_p.head()

import pandas as pd
from prophet import Prophet
model = Prophet()
model.fit(df_p)

future_dates = model.make_future_dataframe(periods=2880)#2880 din = 1 mash
predictions = model.predict(future_dates)
predictions.head()

model.plot(predictions)

model.plot_components(predictions)

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.metrics import mean_squared_error

data = df['Total'].values.reshape(-1, 1)
scaler = MinMaxScaler()
data = scaler.fit_transform(data)

def create_sequences(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

look_back = 24
X, Y = create_sequences(data, look_back)

train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(LSTM(units=50))
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')

model.fit(X_train, Y_train, epochs=100, batch_size=32)

predictions = model.predict(X_test)

predictions = scaler.inverse_transform(predictions)
Y_test = scaler.inverse_transform(Y_test.reshape(-1, 1))

rmse = np.sqrt(mean_squared_error(Y_test, predictions))
print('RMSE:', rmse)

import matplotlib.pyplot as plt

plt.plot(Y_test, label='Actual')
plt.plot(predictions, label='Predictions')
plt.legend()
plt.show()

mae = mean_absolute_error(Y_test, predictions)
print('MAE:', mae)

rmse = np.sqrt(mean_squared_error(Y_test, predictions))
print('RMSE:', rmse)

mape = np.mean(np.abs((Y_test - predictions) / Y_test)) * 100
print('MAPE:', mape)

accuracy_lstm = 100 - mape
print(f"Accuracy of LSTM Model: {accuracy_lstm:.2f}%")

from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# we will use the "Traffic Situation" as target in this model
encoder = LabelEncoder()
df['Traffic Situation'] = encoder.fit_transform(df['Traffic Situation'])
data = df['Traffic Situation'].values

look_back = 24
X, Y = [], []
for i in range(len(data)-look_back-1):
    a = data[i:(i+look_back)]
    X.append(a)
    Y.append(data[i + look_back])
X = np.array(X)
Y = np.array(Y)

train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

model = XGBClassifier()
model.fit(X_train, Y_train)
predictions = model.predict(X_test)

# Decode
predictions = encoder.inverse_transform(predictions)
Y_test = encoder.inverse_transform(Y_test)

accuracy = accuracy_score(Y_test, predictions)
print('Accuracy:', accuracy)

# 1 day/96row
last_values = data[-look_back:]
future_predictions = []
for i in range(96):
    prediction = model.predict(last_values.reshape(1, -1))
    future_predictions.append(prediction[0])
    last_values = np.append(last_values[1:], prediction)

future_predictions = encoder.inverse_transform(future_predictions)
print(future_predictions)

plt.figure(figsize=(18, 6))
plt.plot(np.arange(len(Y_test)), Y_test, label='Actual Traffic Situation', color='green')
plt.plot(np.arange(len(predictions)), predictions, label='Predicted Traffic Situation', color='yellow')
plt.title('Actual vs Predicted Traffic Situation')
plt.xlabel('Time Steps')
plt.ylabel('Traffic Situation')
plt.legend()
plt.show()